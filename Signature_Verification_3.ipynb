{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-539828b07624>, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-539828b07624>\"\u001b[1;36m, line \u001b[1;32m59\u001b[0m\n\u001b[1;33m    if image.shape[0] > height\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "############# THINNING  #############\n",
    "\n",
    "from scipy import weave\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def _thinningIteration(im, iter):\n",
    "    I, M = im, np.zeros(im.shape, np.uint8)\n",
    "    expr = \"\"\"\n",
    "    for (int i = 1; i < NI[0]-1; i++) {\n",
    "        for (int j = 1; j < NI[1]-1; j++) {\n",
    "            int p2 = I2(i-1, j);\n",
    "            int p3 = I2(i-1, j+1);\n",
    "            int p4 = I2(i, j+1);\n",
    "            int p5 = I2(i+1, j+1);\n",
    "            int p6 = I2(i+1, j);\n",
    "            int p7 = I2(i+1, j-1);\n",
    "            int p8 = I2(i, j-1);\n",
    "            int p9 = I2(i-1, j-1);\n",
    "\n",
    "            int A  = (p2 == 0 && p3 == 1) + (p3 == 0 && p4 == 1) +\n",
    "                     (p4 == 0 && p5 == 1) + (p5 == 0 && p6 == 1) +\n",
    "                     (p6 == 0 && p7 == 1) + (p7 == 0 && p8 == 1) +\n",
    "            (p8 == 0 && p9 == 1) + (p9 == 0 && p2 == 1);\n",
    "            int B  = p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9;\n",
    "            int m1 = iter == 0 ? (p2 * p4 * p6) : (p2 * p4 * p8);\n",
    "            int m2 = iter == 0 ? (p4 * p6 * p8) : (p2 * p6 * p8);\n",
    "\n",
    "            if (A == 1 && B >= 2 && B <= 6 && m1 == 0 && m2 == 0) {\n",
    "                M2(i,j) = 1;\n",
    "            }\n",
    "        }\n",
    "    } \n",
    "    \"\"\"\n",
    "\n",
    "    weave.inline(expr, [\"I\", \"iter\", \"M\"])\n",
    "    return (I & ~M)\n",
    "\n",
    "\n",
    "def thinning(src):\n",
    "    dst = src.copy() / 255\n",
    "    prev = np.zeros(src.shape[:2], np.uint8)\n",
    "    diff = None\n",
    "\n",
    "    while True:\n",
    "        dst = _thinningIteration(dst, 0)\n",
    "        dst = _thinningIteration(dst, 1)\n",
    "        diff = np.absolute(dst - prev)\n",
    "        prev = dst.copy()\n",
    "        if np.sum(diff) == 0:\n",
    "            break\n",
    "\n",
    "    return dst * 255\n",
    "\n",
    "############# SCALING #############\n",
    "# Metodo que permite escalar la imagen a un tamaño por default(400)\n",
    "# para que todas las imagenes posean el mismo tamaño\n",
    "def scale(image, height=400):\n",
    "    if image.shape[0] > height\n",
    "        # Obtenemos las filas y columnas\n",
    "        original_h, original_w = np.float32(image.shape[:2])\n",
    "        # Calculamos el ancho que tendra con respecto al alto(400)\n",
    "        width = int( height * ( original_w / original_h ) )\n",
    "        # Escalamos la imagen\n",
    "        image_scaled = cv2.resize(image, (width, height), interpolation = cv2.INTER_LANCZOS4)\n",
    "        # Retornamos la imagen escalada\n",
    "        return image_scaled\n",
    "\n",
    "def crop(image):\n",
    "    # Requiere imagen en Blanco y Negro\n",
    "    ret, _image = cv2.threshold(image, thresh=127, maxval=255, type=cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    kernel = np.ones((20,20), np.uint8)\n",
    "    _image = cv2.dilate(_image, kernel, iterations = 1)\n",
    "    \n",
    "    # Obtenemos los contornos de la imagen\n",
    "    _,contours,hierarchy = cv2.findContours(_image, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "    # Calculamos el Contorno con mayor Area(Vendria a ser nuestra firma)\n",
    "    max_area_contour = cv2.contourArea(contours[0])\n",
    "    max_index = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        index_area_contour = cv2.contourArea(contour)\n",
    "        if index_area_contour > max_area_contour:\n",
    "            max_area_contour = index_area_contour\n",
    "            max_index = index\n",
    "    # Obtenemos los lados de la firma y Recortamos...\n",
    "    cnt = contours[max_index]    \n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    image = image[y:y+h,x:x+w]\n",
    "    \n",
    "    return image\n",
    "            \n",
    "def normalize(image, width=400, height=250):\n",
    "    image = cv2.resize(image, (width, height), interpolation = cv2.INTER_LANCZOS4)\n",
    "    return image\n",
    "\n",
    "############# PREPROCESSING #############\n",
    "def preprocess(image, showProcess=False):\n",
    "    #GrayScale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' GrayScale', image)\n",
    "        cv2.imwrite('./images/GrayScale.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    #Scaling\n",
    "    image = scale(image, height=400)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Scaled', image)\n",
    "        cv2.imwrite('./images/Scaled.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    #Denoising\n",
    "    image = cv2.fastNlMeansDenoising(image, \n",
    "                                     dst=None, \n",
    "                                     h=6, \n",
    "                                     templateWindowSize=7, \n",
    "                                     searchWindowSize=21)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Denoised', image)\n",
    "        cv2.imwrite('./images/Denoised.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "   \n",
    "    # Cropping\n",
    "    image = crop(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Cropped', image)\n",
    "        cv2.imwrite('./images/Cropped.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    # Normalization\n",
    "    image = normalize(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Normalized', image)\n",
    "        cv2.imwrite('./images/Normalized.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    # Thresholding Inverse\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Binarizacion inverse', image)\n",
    "        cv2.imwrite('./images/Threshold1.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    # Thinning\n",
    "    image = thinning(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Thining', image)\n",
    "        cv2.imwrite('./images/Thinning.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    # Thresholding 2\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Binarizacion', image)\n",
    "        cv2.imwrite('./images/Threshold2.jpg',image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    \n",
    "    return image\n",
    "\n",
    "def dilate4Colors(image):\n",
    "    # DILATION \n",
    "    image_color_black = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_red   = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_green = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_blue  = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    image_color_black[image == 0] = [0, 0, 0]\n",
    "    image_color_red  [image == 0] = [0, 0, 255]\n",
    "    image_color_green[image == 0] = [0, 255, 0]\n",
    "    image_color_blue [image == 0] = [255, 0, 0]\n",
    "\n",
    "    kernel_3  = np.ones( (3,3) , np.uint8)\n",
    "    kernel_6  = np.ones( (6,6) , np.uint8)\n",
    "    kernel_10 = np.ones((10,10), np.uint8)\n",
    "    kernel_16 = np.ones((16,16), np.uint8)\n",
    "\n",
    "    image_3  = cv2.erode(image_color_black, kernel_3 , iterations = 1)\n",
    "    image_6  = cv2.erode(image_color_red  , kernel_6 , iterations = 1)\n",
    "    image_10 = cv2.erode(image_color_green, kernel_10, iterations = 1)\n",
    "    image_16 = cv2.erode(image_color_blue , kernel_16, iterations = 1)\n",
    "\n",
    "    # FUSION\n",
    "    img_fusion_1 = cv2.bitwise_and(image_16,image_10)\n",
    "    img_fusion_1[cv2.threshold(cv2.cvtColor(img_fusion_1, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY)[1] == 0] = [0, 255, 0]\n",
    "\n",
    "    img_fusion_2 = cv2.bitwise_and(img_fusion_1, image_6)\n",
    "    img_fusion_2[cv2.threshold(cv2.cvtColor(img_fusion_2, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY)[1] == 0] = [0, 0, 255]\n",
    "\n",
    "    img_fusion_3 = cv2.bitwise_and(img_fusion_2, image_3)\n",
    "\n",
    "    return img_fusion_3\n",
    "\n",
    "\n",
    "def obtenerFeatures(image):\n",
    "    # GEOMETRIC FEATURES\n",
    "\n",
    "    imHeight, imWidth = np.float32(image.shape[:2])\n",
    "    totalPixels = imHeight*imWidth\n",
    "\n",
    "    # Aspect Ratio\n",
    "    aspectRatio = imHeight / imWidth\n",
    "    #print 'Aspect Ratio : ', aspectRatio\n",
    "\n",
    "    # Density Ratio\n",
    "    whitePixelsHalfLeft  = cv2.countNonZero(image[:,:image.shape[1]/2])\n",
    "    signaturePixelsHalfLeft = totalPixels/2 - whitePixelsHalfLeft\n",
    "    whitePixelsHalfRight = cv2.countNonZero(image[:,image.shape[1]/2:])\n",
    "    signaturePixelsHalfRight = totalPixels/2 - whitePixelsHalfRight\n",
    "\n",
    "    densityRatio = signaturePixelsHalfLeft / whitePixelsHalfRight\n",
    "\n",
    "    #print 'Density Ratio : ' , densityRatio\n",
    "\n",
    "    # Ocupancy Ratio\n",
    "    ## Negro 0 (cero)\n",
    "    ## Otros(Blanco) NonZero\n",
    "    totalWhitePixels = cv2.countNonZero(image)\n",
    "    signaturePixels = totalPixels-totalWhitePixels\n",
    "    occupancyRatio = signaturePixels / totalWhitePixels\n",
    "    #print 'Occupancy Ratio : ', occupancyRatio\n",
    "\n",
    "    # Harris Corners / GoodFeatures to Track\n",
    "    #cornersArr = cv2.cornerHarris(image, 3, 3, 0.05)\n",
    "    cornersArr = cv2.goodFeaturesToTrack(image, 500, 0.01, 15)\n",
    "    corners = len(cornersArr)\n",
    "    #print 'Corners : ' , corners\n",
    "    \n",
    "    # Imagen usada como base para comparar contra otras nuevas\n",
    "    img_base = cv2.imread('images/signatures/drsc/legit_1_x5.jpg')\n",
    "    img_entry = dilate4Colors(image)\n",
    "    img_merged = cv2.bitwise_xor(img_base,img_entry)\n",
    "\n",
    "    #cv2.imshow('im2',img_base)\n",
    "    #cv2.imshow('im3',img_entry)\n",
    "    #cv2.imshow('merged',img_merged)\n",
    "\n",
    "    # NEGRO\n",
    "    BLACK_MIN = np.array([0, 0, 0], np.uint8)\n",
    "    BLACK_MAX = np.array([50, 50, 50], np.uint8)\n",
    "    dst_black = cv2.inRange(img_merged, BLACK_MIN, BLACK_MAX)\n",
    "    #cv2.imshow('Black',dst_black)\n",
    "    no_black = cv2.countNonZero(dst_black)\n",
    "    #print('The number of black pixels is: ' + str(no_black))\n",
    "\n",
    "    # ROJO\n",
    "    RED_MIN = np.array([0, 0, 200], np.uint8)\n",
    "    RED_MAX = np.array([50, 50, 255], np.uint8)\n",
    "    dst_red = cv2.inRange(img_merged, RED_MIN, RED_MAX)\n",
    "    #cv2.imshow('Red',dst_red)\n",
    "    no_red = cv2.countNonZero(dst_red)\n",
    "    #print('The number of red pixels is: ' + str(no_red))\n",
    "\n",
    "    # VERDE\n",
    "    GREEN_MIN = np.array([0, 200, 0], np.uint8)\n",
    "    GREEN_MAX = np.array([50, 255, 50], np.uint8)\n",
    "    dst_green = cv2.inRange(img_merged, GREEN_MIN, GREEN_MAX)\n",
    "    #cv2.imshow('Green',dst_green)\n",
    "    no_green = cv2.countNonZero(dst_green)\n",
    "    #print('The number of green pixels is: ' + str(no_green))\n",
    "\n",
    "    # AZUL\n",
    "    BLUE_MIN = np.array([200, 0, 0], np.uint8)\n",
    "    BLUE_MAX = np.array([255, 50, 50], np.uint8)\n",
    "    dst_blue = cv2.inRange(img_merged, BLUE_MIN, BLUE_MAX)\n",
    "    #cv2.imshow('Blue',dst_blue)\n",
    "    no_blue = cv2.countNonZero(dst_blue)\n",
    "    #print('The number of blue pixels is: ' + str(no_blue))\n",
    "\n",
    "    # BLANCO\n",
    "    WHITE_MIN = np.array([200, 200, 200], np.uint8)\n",
    "    WHITE_MAX = np.array([255, 255, 255], np.uint8)\n",
    "    dst_white = cv2.inRange(img_merged, WHITE_MIN, WHITE_MAX)\n",
    "    #cv2.imshow('White',dst_white)\n",
    "    no_white = cv2.countNonZero(dst_white)\n",
    "    #print('The number of white pixels is: ' + str(no_white))\n",
    "\n",
    "    # CIAN\n",
    "    CIAN_MIN = np.array([200, 200, 0], np.uint8)\n",
    "    CIAN_MAX = np.array([255, 255, 50], np.uint8)\n",
    "    dst_cian = cv2.inRange(img_merged, CIAN_MIN, CIAN_MAX)\n",
    "    #cv2.imshow('Cian',dst_cian)\n",
    "    no_cian = cv2.countNonZero(dst_cian)\n",
    "    #print('The number of cian pixels is: ' + str(no_cian))\n",
    "\n",
    "    # MAGENTA\n",
    "    MAGENTA_MIN = np.array([200, 0, 200], np.uint8)\n",
    "    MAGENTA_MAX = np.array([255, 50, 255], np.uint8)\n",
    "    dst_magenta = cv2.inRange(img_merged, MAGENTA_MIN, MAGENTA_MAX)\n",
    "    #cv2.imshow('Magenta',dst_magenta)\n",
    "    no_magenta = cv2.countNonZero(dst_magenta)\n",
    "    #print('The number of magenta pixels is: ' + str(no_magenta))\n",
    "\n",
    "    # AMARILLO\n",
    "    YELLOW_MIN = np.array([0, 200, 200], np.uint8)\n",
    "    YELLOW_MAX = np.array([50, 255, 255], np.uint8)\n",
    "    dst_yellow= cv2.inRange(img_merged, YELLOW_MIN, YELLOW_MAX)\n",
    "    #cv2.imshow('Yellow',dst_yellow)\n",
    "    no_yellow = cv2.countNonZero(dst_yellow)\n",
    "    #print('The number of yellow pixels is: ' + str(no_yellow))\n",
    "\n",
    "    # FONDO 1\n",
    "    FONDO1_MIN = np.array([134, 130, 200], np.uint8)\n",
    "    FONDO1_MAX = np.array([183, 180, 255], np.uint8)\n",
    "    dst_fondo1= cv2.inRange(img_merged, FONDO1_MIN, FONDO1_MAX)\n",
    "    #cv2.imshow('Fondo 1',dst_fondo1)\n",
    "    no_fondo1 = cv2.countNonZero(dst_fondo1)\n",
    "    #print('The number of fondo1 pixels is: ' + str(no_fondo1))\n",
    "\n",
    "    # FONDO 2\n",
    "    FONDO2_MIN = np.array([71, 75, 0], np.uint8)\n",
    "    FONDO2_MAX = np.array([121, 125, 50], np.uint8)\n",
    "    dst_fondo2= cv2.inRange(img_merged, FONDO2_MIN, FONDO2_MAX)\n",
    "    #cv2.imshow('Fondo 2',dst_fondo2)\n",
    "    no_fondo2 = cv2.countNonZero(dst_fondo2)\n",
    "    #print('The number of fondo2 pixels is: ' + str(no_fondo2))\n",
    "    \n",
    "    featuresX = [\n",
    "        aspectRatio,\n",
    "        densityRatio,\n",
    "        occupancyRatio,\n",
    "        corners,\n",
    "        no_red,\n",
    "        no_green,\n",
    "        no_blue,\n",
    "        no_white,\n",
    "        no_cian,\n",
    "        no_magenta,\n",
    "        no_yellow,\n",
    "        no_fondo1,\n",
    "        no_fondo2 ]\n",
    "    return featuresX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\build\\master_winpack-bindings-win64-vc14-static\\opencv\\modules\\core\\src\\arithm.cpp:225: error: (-209) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function cv::binary_op\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3d94085e3b32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#cv2.waitKey(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfeaturesX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobtenerFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mfeaturesY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-d941831272f3>\u001b[0m in \u001b[0;36mobtenerFeatures\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mimg_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/signatures/drsc/legit_1_x5.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[0mimg_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdilateBy4Colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[0mimg_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_xor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_entry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;31m#cv2.imshow('im2',img_base)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\build\\master_winpack-bindings-win64-vc14-static\\opencv\\modules\\core\\src\\arithm.cpp:225: error: (-209) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function cv::binary_op\n"
     ]
    }
   ],
   "source": [
    "##### MAIN FUNCTION ########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "featuresX = []\n",
    "featuresY = []\n",
    "\n",
    "# LEGIT SIGNATURES\n",
    "for i in range(2,10):\n",
    "    ruta_imagen = \"images/signatures/drsc/legit_\"+str(i)\n",
    "    extension_imagen = \".jpg\"\n",
    "    image = cv2.imread(ruta_imagen + extension_imagen)\n",
    "    image = preprocess(image, False)\n",
    "    #cv2.imshow('Signature PreProcessed', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    #img_dilated = dilate4Colors(image)\n",
    "    #cv2.imshow('Signature Dilated x5', img_dilated)\n",
    "    #cv2.imwrite(ruta_imagen+\"_x5\"+extension_imagen, img_dilated)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    featuresX.append(obtenerFeatures(image))\n",
    "    featuresY.append(1)\n",
    "    \n",
    "# FORGE SIGNATURES   \n",
    "for i in range(2,9):\n",
    "    ruta_imagen = \"images/signatures/drsc/forgery_\"+str(i)\n",
    "    extension_imagen = \".jpg\"\n",
    "    image = cv2.imread(ruta_imagen + extension_imagen)\n",
    "    image = preprocess(image, False)\n",
    "    #cv2.imshow('Signature PreProcessed', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    #img_dilated = dilate4Colors(image)\n",
    "    #cv2.imshow('Signature Dilated x5', img_dilated)\n",
    "    #cv2.imwrite(ruta_imagen+\"_x5\"+extension_imagen, img_dilated)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    featuresX.append(obtenerFeatures(image))\n",
    "    featuresY.append(0)\n",
    "\n",
    "print \"Caracteristicas X : \", featuresX\n",
    "print \"Caracteristicas Y : \", featuresY\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dasayef.ruben\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Py27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'featuresX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d09e0d3aca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m## random_state, ejemplos random solo para fines educativos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeaturesY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 5.Feature Scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'featuresX' is not defined"
     ]
    }
   ],
   "source": [
    "# SCIKIT LEARN \n",
    "\n",
    "# 1.Importing the dataset\n",
    "# 2.Taking care of missing data\n",
    "# 3.Encoding categorical data\n",
    "\n",
    "# 4.Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "## random_state, ejemplos random solo para fines educativos\n",
    "x_train, x_test, y_train, y_test = train_test_split(featuresX,featuresY,test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 5.Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)\n",
    "\n",
    "print 'TRAIN DATA'\n",
    "print x_train\n",
    "print y_train\n",
    "\n",
    "print 'TEST DATA'\n",
    "print x_test\n",
    "print y_test\n",
    "\n",
    "# SCIKIT LEARN - SVM\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "_svm = svm.SVC()\n",
    "\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "\n",
    "x_test = x_test\n",
    "\n",
    "_svm.fit(x_train,y_train)\n",
    "\n",
    "val_to_predict = x_test\n",
    "\n",
    "svm_prediction = _svm.predict(val_to_predict)\n",
    "\n",
    "print(\"prediccion svm\", svm_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROCESO DE UNA SOLA IMAGEN\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "_img_1 = cv2.imread('./images/signatures/drsc/legit_1.jpg')\n",
    "_img_1 = preprocess(_img_1, True)\n",
    "#cv2.imshow('_img_1',_img_1)\n",
    "\"\"\"\n",
    "_img_2 = cv2.imread('./images/signatures/drsc/legit_2.jpg')\n",
    "_img_2 = preprocess(_img_2, False)\n",
    "#_img_2 = dilate4Colors(_img_2)\n",
    "_img_2 = cv2.cvtColor(_img_2, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imshow('_img_2',_img_2)\n",
    "\n",
    "_merged_img = cv2.bitwise_xor(_img_1, _img_2)\n",
    "cv2.imshow('Merged ', _merged_img)\n",
    "\n",
    "\"\"\"\n",
    "_img_3 = cv2.imread('./images/si<gnatures/drsc/legit_3.jpg')\n",
    "_img_3 = preprocess(_img_3, False)\n",
    "cv2.imshow('_img_3',_img_3)\n",
    "\"\"\"\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250L, 400L)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_img_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBNDO DILATACIONx4\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "_img_x = cv2.imread('./images/signatures/drsc/legit_2.jpg')\n",
    "_img_x = preprocess(_img_x, False)\n",
    "\n",
    "#cv2.imshow('dilate 4 colors', _img_2)\n",
    "dilate4Colors(_img_x)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dasayef.ruben\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Py27\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 250 but corresponding boolean dimension is 400\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0L, 3L), dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
