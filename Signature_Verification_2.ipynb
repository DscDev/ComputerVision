{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGNATURE VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### THINNING ALGORITHM #############\n",
    "\n",
    "from scipy import weave\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def _thinningIteration(im, iter):\n",
    "    I, M = im, np.zeros(im.shape, np.uint8)\n",
    "    expr = \"\"\"\n",
    "    for (int i = 1; i < NI[0]-1; i++) {\n",
    "        for (int j = 1; j < NI[1]-1; j++) {\n",
    "            int p2 = I2(i-1, j);\n",
    "            int p3 = I2(i-1, j+1);\n",
    "            int p4 = I2(i, j+1);\n",
    "            int p5 = I2(i+1, j+1);\n",
    "            int p6 = I2(i+1, j);\n",
    "            int p7 = I2(i+1, j-1);\n",
    "            int p8 = I2(i, j-1);\n",
    "            int p9 = I2(i-1, j-1);\n",
    "\n",
    "            int A  = (p2 == 0 && p3 == 1) + (p3 == 0 && p4 == 1) +\n",
    "                     (p4 == 0 && p5 == 1) + (p5 == 0 && p6 == 1) +\n",
    "                     (p6 == 0 && p7 == 1) + (p7 == 0 && p8 == 1) +\n",
    "            (p8 == 0 && p9 == 1) + (p9 == 0 && p2 == 1);\n",
    "            int B  = p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9;\n",
    "            int m1 = iter == 0 ? (p2 * p4 * p6) : (p2 * p4 * p8);\n",
    "            int m2 = iter == 0 ? (p4 * p6 * p8) : (p2 * p6 * p8);\n",
    "\n",
    "            if (A == 1 && B >= 2 && B <= 6 && m1 == 0 && m2 == 0) {\n",
    "                M2(i,j) = 1;\n",
    "            }\n",
    "        }\n",
    "    } \n",
    "    \"\"\"\n",
    "\n",
    "    weave.inline(expr, [\"I\", \"iter\", \"M\"])\n",
    "    return (I & ~M)\n",
    "\n",
    "\n",
    "def thinning(src):\n",
    "    dst = src.copy() / 255\n",
    "    prev = np.zeros(src.shape[:2], np.uint8)\n",
    "    diff = None\n",
    "\n",
    "    while True:\n",
    "        dst = _thinningIteration(dst, 0)\n",
    "        dst = _thinningIteration(dst, 1)\n",
    "        diff = np.absolute(dst - prev)\n",
    "        prev = dst.copy()\n",
    "        if np.sum(diff) == 0:\n",
    "            break\n",
    "\n",
    "    return dst * 255\n",
    "\n",
    "############# ESCALAMIENTO #############\n",
    "# Metodo que permite escalar la imagen a un tamaño por default(100)\n",
    "# para que todas las imagenes posean el mismo tamaño\n",
    "def scale(image, height=500):\n",
    "    # Obtenemos las filas y columnas\n",
    "    original_h, original_w = np.float32(image.shape[:2])\n",
    "    # Calculamos el ancho que tendra con respecto al alto(100)\n",
    "    width = int( height * ( original_w / original_h ) )\n",
    "    # Escalamos la imagen\n",
    "    image_scaled = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    # Retornamos la imagen escalada\n",
    "    return image_scaled\n",
    "\n",
    "def normalize(image):\n",
    "    # dilating image\n",
    "    img = image.copy()\n",
    "    kernel = np.ones((20,20), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations = 1)\n",
    "\n",
    "    # Binarization\n",
    "    ret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    _,contours,hierarchy = cv2.findContours(255 - thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Buscamos el contorno mas grande\n",
    "    max_area_contour = cv2.contourArea(contours[0])\n",
    "    max_index = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        index_area_contour = cv2.contourArea(contour)\n",
    "        if index_area_contour > max_area_contour:\n",
    "            max_area_contour = index_area_contour\n",
    "            max_index = index\n",
    "\n",
    "    cnt = contours[max_index]    \n",
    "\n",
    "    # Bounding Rect\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Cropping\n",
    "    image = image[y:y+h,x:x+w]\n",
    "    return image\n",
    "\n",
    "############# PREPROCESSING #############\n",
    "def preprocess(image, showProcess=False):\n",
    "    #GrayScale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' GrayScale', image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    #Scaling 1\n",
    "    image = scale(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Scaled 1', image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    # Normalizing\n",
    "    image = normalize(image);\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Normalized', image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    #Scaling 2\n",
    "    image = scale(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Scaled 2', image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    # Binarizacion 1\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Binarizacion inv 1', image)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    # Dilation\n",
    "    #image = cv2.dilate(image, np.ones((5,5),np.uint8))\n",
    "    #if showProcess:\n",
    "    #    cv2.imshow(' Erosino ', image)\n",
    "    #    cv2.waitKey(0)\n",
    "    \n",
    "    # Erosion\n",
    "    #image = cv2.erode(image, np.ones((7,7),np.uint8))\n",
    "    #if showProcess:\n",
    "    #    cv2.imshow(' Erosino ', image)\n",
    "    #    cv2.waitKey(0)\n",
    "    \n",
    "    # Thinning\n",
    "    image = thinning(image)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Thining', image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    # Binarizacion inv 2\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    if showProcess:\n",
    "        cv2.imshow(' Binarizacion inv 2', image)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def dilatex5(image):\n",
    "    # DILATION \n",
    "    image_color_black = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_red = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_green= cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    image_color_blue = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    image_color_black[image == 0] = [0, 0, 0]\n",
    "    image_color_red[image == 0]   = [0, 0, 255]\n",
    "    image_color_green[image == 0] = [0, 255, 0]\n",
    "    image_color_blue[image == 0]  = [255, 0, 0]\n",
    "\n",
    "    kernel_3 = np.ones((3,3), np.uint8)\n",
    "    kernel_6 = np.ones((6,6), np.uint8)\n",
    "    kernel_10 = np.ones((10,10), np.uint8) \n",
    "    kernel_16 = np.ones((16,16), np.uint8)\n",
    "\n",
    "    image_3 = cv2.erode(image_color_black, kernel_3, iterations = 1)\n",
    "    image_6 = cv2.erode(image_color_red, kernel_6, iterations = 1)\n",
    "    image_10 = cv2.erode(image_color_green, kernel_10, iterations = 1)\n",
    "    image_16 = cv2.erode(image_color_blue, kernel_16, iterations = 1)\n",
    "\n",
    "    #cv2.imshow(\"Kernel 3\", image_3)\n",
    "    #cv2.imshow(\"Kernel 6\", image_6)\n",
    "    #cv2.imshow(\"Kernel 10\", image_10)\n",
    "    #cv2.imshow(\"Kernel 16\", image_16)\n",
    "\n",
    "    # FUSION\n",
    "    img_fusion_1 = cv2.bitwise_and(image_16,image_10)\n",
    "    img_fusion_1[cv2.threshold(cv2.cvtColor(img_fusion_1, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY)[1] == 0] = [0, 255, 0]\n",
    "\n",
    "    img_fusion_2 = cv2.bitwise_and(img_fusion_1, image_6)\n",
    "    img_fusion_2[cv2.threshold(cv2.cvtColor(img_fusion_2, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY)[1] == 0] = [0, 0, 255]\n",
    "\n",
    "    img_fusion_3 = cv2.bitwise_and(img_fusion_2, image_3)\n",
    "\n",
    "    return img_fusion_3\n",
    "\n",
    "\n",
    "def obtenerFeatures(image):\n",
    "    # GEOMETRIC FEATURES\n",
    "\n",
    "    imHeight, imWidth = np.float32(image.shape[:2])\n",
    "    totalPixels = imHeight*imWidth\n",
    "\n",
    "    # Aspect Ratio\n",
    "    aspectRatio = imHeight / imWidth\n",
    "    #print 'Aspect Ratio : ', aspectRatio\n",
    "\n",
    "    # Density Ratio\n",
    "    whitePixelsHalfLeft  = cv2.countNonZero(image[:,:image.shape[1]/2])\n",
    "    signaturePixelsHalfLeft = totalPixels/2 - whitePixelsHalfLeft\n",
    "    whitePixelsHalfRight = cv2.countNonZero(image[:,image.shape[1]/2:])\n",
    "    signaturePixelsHalfRight = totalPixels/2 - whitePixelsHalfRight\n",
    "\n",
    "    densityRatio = signaturePixelsHalfLeft / whitePixelsHalfRight\n",
    "\n",
    "    #print 'Density Ratio : ' , densityRatio\n",
    "\n",
    "    # Ocupancy Ratio\n",
    "    ## Negro 0 (cero)\n",
    "    ## Otros(Blanco) NonZero\n",
    "    totalWhitePixels = cv2.countNonZero(image)\n",
    "    signaturePixels = totalPixels-totalWhitePixels\n",
    "    occupancyRatio = signaturePixels / totalWhitePixels\n",
    "    #print 'Occupancy Ratio : ', occupancyRatio\n",
    "\n",
    "    # Harris Corners / GoodFeatures to Track\n",
    "    #cornersArr = cv2.cornerHarris(image, 3, 3, 0.05)\n",
    "    cornersArr = cv2.goodFeaturesToTrack(image, 500, 0.01, 15)\n",
    "    corners = len(cornersArr)\n",
    "    #print 'Corners : ' , corners\n",
    "    \n",
    "    # Imagen usada como base para comparar contra otras nuevas\n",
    "    img_base = cv2.imread('images/signatures/drsc/legit_1_x5.jpg')\n",
    "    img_entry = dilatex5(image)\n",
    "    img_merged = cv2.bitwise_xor(img_base,img_entry)\n",
    "\n",
    "    #cv2.imshow('im2',img_base)\n",
    "    #cv2.imshow('im3',img_entry)\n",
    "    #cv2.imshow('merged',img_merged)\n",
    "\n",
    "    # NEGRO\n",
    "    BLACK_MIN = np.array([0, 0, 0], np.uint8)\n",
    "    BLACK_MAX = np.array([50, 50, 50], np.uint8)\n",
    "    dst_black = cv2.inRange(img_merged, BLACK_MIN, BLACK_MAX)\n",
    "    #cv2.imshow('Black',dst_black)\n",
    "    no_black = cv2.countNonZero(dst_black)\n",
    "    #print('The number of black pixels is: ' + str(no_black))\n",
    "\n",
    "    # ROJO\n",
    "    RED_MIN = np.array([0, 0, 200], np.uint8)\n",
    "    RED_MAX = np.array([50, 50, 255], np.uint8)\n",
    "    dst_red = cv2.inRange(img_merged, RED_MIN, RED_MAX)\n",
    "    #cv2.imshow('Red',dst_red)\n",
    "    no_red = cv2.countNonZero(dst_red)\n",
    "    #print('The number of red pixels is: ' + str(no_red))\n",
    "\n",
    "    # VERDE\n",
    "    GREEN_MIN = np.array([0, 200, 0], np.uint8)\n",
    "    GREEN_MAX = np.array([50, 255, 50], np.uint8)\n",
    "    dst_green = cv2.inRange(img_merged, GREEN_MIN, GREEN_MAX)\n",
    "    #cv2.imshow('Green',dst_green)\n",
    "    no_green = cv2.countNonZero(dst_green)\n",
    "    #print('The number of green pixels is: ' + str(no_green))\n",
    "\n",
    "    # AZUL\n",
    "    BLUE_MIN = np.array([200, 0, 0], np.uint8)\n",
    "    BLUE_MAX = np.array([255, 50, 50], np.uint8)\n",
    "    dst_blue = cv2.inRange(img_merged, BLUE_MIN, BLUE_MAX)\n",
    "    #cv2.imshow('Blue',dst_blue)\n",
    "    no_blue = cv2.countNonZero(dst_blue)\n",
    "    #print('The number of blue pixels is: ' + str(no_blue))\n",
    "\n",
    "    # BLANCO\n",
    "    WHITE_MIN = np.array([200, 200, 200], np.uint8)\n",
    "    WHITE_MAX = np.array([255, 255, 255], np.uint8)\n",
    "    dst_white = cv2.inRange(img_merged, WHITE_MIN, WHITE_MAX)\n",
    "    #cv2.imshow('White',dst_white)\n",
    "    no_white = cv2.countNonZero(dst_white)\n",
    "    #print('The number of white pixels is: ' + str(no_white))\n",
    "\n",
    "    # CIAN\n",
    "    CIAN_MIN = np.array([200, 200, 0], np.uint8)\n",
    "    CIAN_MAX = np.array([255, 255, 50], np.uint8)\n",
    "    dst_cian = cv2.inRange(img_merged, CIAN_MIN, CIAN_MAX)\n",
    "    #cv2.imshow('Cian',dst_cian)\n",
    "    no_cian = cv2.countNonZero(dst_cian)\n",
    "    #print('The number of cian pixels is: ' + str(no_cian))\n",
    "\n",
    "    # MAGENTA\n",
    "    MAGENTA_MIN = np.array([200, 0, 200], np.uint8)\n",
    "    MAGENTA_MAX = np.array([255, 50, 255], np.uint8)\n",
    "    dst_magenta = cv2.inRange(img_merged, MAGENTA_MIN, MAGENTA_MAX)\n",
    "    #cv2.imshow('Magenta',dst_magenta)\n",
    "    no_magenta = cv2.countNonZero(dst_magenta)\n",
    "    #print('The number of magenta pixels is: ' + str(no_magenta))\n",
    "\n",
    "    # AMARILLO\n",
    "    YELLOW_MIN = np.array([0, 200, 200], np.uint8)\n",
    "    YELLOW_MAX = np.array([50, 255, 255], np.uint8)\n",
    "    dst_yellow= cv2.inRange(img_merged, YELLOW_MIN, YELLOW_MAX)\n",
    "    #cv2.imshow('Yellow',dst_yellow)\n",
    "    no_yellow = cv2.countNonZero(dst_yellow)\n",
    "    #print('The number of yellow pixels is: ' + str(no_yellow))\n",
    "\n",
    "    # FONDO 1\n",
    "    FONDO1_MIN = np.array([134, 130, 200], np.uint8)\n",
    "    FONDO1_MAX = np.array([183, 180, 255], np.uint8)\n",
    "    dst_fondo1= cv2.inRange(img_merged, FONDO1_MIN, FONDO1_MAX)\n",
    "    #cv2.imshow('Fondo 1',dst_fondo1)\n",
    "    no_fondo1 = cv2.countNonZero(dst_fondo1)\n",
    "    #print('The number of fondo1 pixels is: ' + str(no_fondo1))\n",
    "\n",
    "    # FONDO 2\n",
    "    FONDO2_MIN = np.array([71, 75, 0], np.uint8)\n",
    "    FONDO2_MAX = np.array([121, 125, 50], np.uint8)\n",
    "    dst_fondo2= cv2.inRange(img_merged, FONDO2_MIN, FONDO2_MAX)\n",
    "    #cv2.imshow('Fondo 2',dst_fondo2)\n",
    "    no_fondo2 = cv2.countNonZero(dst_fondo2)\n",
    "    #print('The number of fondo2 pixels is: ' + str(no_fondo2))\n",
    "    \n",
    "    featuresX = [\n",
    "        aspectRatio,\n",
    "        densityRatio,\n",
    "        occupancyRatio,\n",
    "        corners,\n",
    "        no_red,\n",
    "        no_green,\n",
    "        no_blue,\n",
    "        no_white,\n",
    "        no_cian,\n",
    "        no_magenta,\n",
    "        no_yellow,\n",
    "        no_fondo1,\n",
    "        no_fondo2 ]\n",
    "    return featuresX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\build\\master_winpack-bindings-win64-vc14-static\\opencv\\modules\\core\\src\\arithm.cpp:225: error: (-209) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function cv::binary_op\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-909b83837d2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#cv2.waitKey(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfeaturesX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobtenerFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mfeaturesY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-0f231073783f>\u001b[0m in \u001b[0;36mobtenerFeatures\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[0mimg_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/signatures/drsc/legit_1_x5.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mimg_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdilatex5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mimg_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_xor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_entry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m#cv2.imshow('im2',img_base)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\build\\master_winpack-bindings-win64-vc14-static\\opencv\\modules\\core\\src\\arithm.cpp:225: error: (-209) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function cv::binary_op\n"
     ]
    }
   ],
   "source": [
    "##### MAIN FUNCTION ########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "featuresX = []\n",
    "featuresY = []\n",
    "\n",
    "# LEGIT SIGNATURES\n",
    "for i in range(2,10):\n",
    "    ruta_imagen = \"images/signatures/drsc/legit_\"+str(i)\n",
    "    extension_imagen = \".jpg\"\n",
    "    image = cv2.imread(ruta_imagen + extension_imagen)\n",
    "    image = preprocess(image, True)\n",
    "    #cv2.imshow('Signature PreProcessed', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    #img_dilated = dilatex5(image)\n",
    "    #cv2.imshow('Signature Dilated x5', img_dilated)\n",
    "    #cv2.imwrite(ruta_imagen+\"_x5\"+extension_imagen, img_dilated)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    featuresX.append(obtenerFeatures(image))\n",
    "    featuresY.append(1)\n",
    "    \n",
    "# FORGE SIGNATURES   \n",
    "for i in range(2,9):\n",
    "    ruta_imagen = \"images/signatures/drsc/forgery_\"+str(i)\n",
    "    extension_imagen = \".jpg\"\n",
    "    image = cv2.imread(ruta_imagen + extension_imagen)\n",
    "    image = preprocess(image, False)\n",
    "    #cv2.imshow('Signature PreProcessed', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    #img_dilated = dilatex5(image)\n",
    "    #cv2.imshow('Signature Dilated x5', img_dilated)\n",
    "    #cv2.imwrite(ruta_imagen+\"_x5\"+extension_imagen, img_dilated)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    featuresX.append(obtenerFeatures(image))\n",
    "    featuresY.append(0)\n",
    "\n",
    "print \"Caracteristicas X : \", featuresX\n",
    "print \"Caracteristicas Y : \", featuresY\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n",
      "[[ 0.         -0.02627448  0.60556195  0.79821011 -1.93566697 -2.15136922\n",
      "  -1.88577421  1.62388981  1.48097027  1.40663678  1.09059061  1.24367596\n",
      "  -0.21340122]\n",
      " [ 0.         -1.2036286   0.28044132 -0.05701501 -0.09522765 -0.15778377\n",
      "  -0.57174839  0.29563807  0.25731701  0.25904431  0.25026465  1.01640523\n",
      "  -1.14460657]\n",
      " [ 0.          0.36427916  0.59025936  0.28507504  0.47802394  1.08445038\n",
      "   1.00716011 -0.17113409 -0.1521903  -0.17739711 -0.20110609 -0.80176065\n",
      "   0.95060546]\n",
      " [ 0.         -0.77543754 -1.49976585 -1.42537519  0.34979661  0.40823421\n",
      "   0.47739476 -1.26388021 -1.3753026  -1.47828317 -1.64275225 -1.33205903\n",
      "   0.13580078]\n",
      " [ 0.         -0.23451223  1.13367123  1.14030015 -0.50630938  0.25796395\n",
      "  -0.51981061  0.81422146  0.82208005  0.83940357  0.71495577  0.56186376\n",
      "  -0.56260323]\n",
      " [ 0.         -0.05079793 -0.77438311  0.37059755 -0.91361973 -0.77890085\n",
      "  -1.53779109  0.49628886  0.40067161  0.46484214  0.71571693  1.54670361\n",
      "  -0.79540457]\n",
      " [ 0.         -0.76286124 -0.46877238 -1.16880766  2.27320656  2.05118905\n",
      "   1.45382501 -1.55543617 -1.50405126 -1.23310717 -1.22677568 -1.55932976\n",
      "   2.46381414]\n",
      " [ 0.          1.53828964  1.22937848  1.22582266 -0.29888282 -0.18282882\n",
      "  -0.67562395  0.81469247  0.93459989  1.00582323  1.13664108  0.1830792\n",
      "  -0.56260323]\n",
      " [ 0.          0.14714761 -1.04933829 -1.16880766  0.96076213 -0.04257657\n",
      "   0.49816987 -1.1465984  -1.09616684 -1.23357596 -1.15408444 -0.65024682\n",
      "   0.25220145]\n",
      " [ 0.         -1.55834081 -1.66766042 -1.42537519  0.28191156  0.44329727\n",
      "   1.04351655 -1.09290312 -1.16324598 -1.22138747 -1.14647279 -1.02903138\n",
      "  -0.32980189]\n",
      " [ 0.          2.01535917  0.54052782  0.19955253  0.13105587  0.01252252\n",
      "   0.55530143  0.12089289  0.29410234  0.27451431  0.24569766  0.33459303\n",
      "   0.95060546]\n",
      " [ 0.          0.54677725  1.08007989  1.22582266 -0.72505012 -0.94419813\n",
      "   0.15538052  1.06432844  1.10121581  1.09348654  1.21732455  0.48610685\n",
      "  -1.14460657]]\n",
      "[0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "TEST DATA\n",
      "[[ 0.         -1.83066405 -0.96533371 -1.08328514  0.41013889  0.65367563\n",
      "   1.4330499  -0.85645547 -0.8402924  -0.84213817 -0.88767675 -0.80176065\n",
      "   0.95060546]\n",
      " [ 0.         -1.63310164 -1.36618951 -1.25433017  1.40955778  0.44329727\n",
      "  -0.54058572 -1.32369864 -1.37854836 -1.46609469 -1.34703972 -0.72600374\n",
      "   0.01940011]\n",
      " [ 0.          1.03616743  0.70120947  0.88373262 -0.66470785 -0.67872067\n",
      "  -0.0991146   0.85849652  0.92432164  1.20458925  1.41104099  0.86489141\n",
      "  -0.44620256]]\n",
      "[1, 1, 0]\n",
      "('prediccion svm', array([1, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# SCIKIT LEARN \n",
    "\n",
    "# 1.Importing the dataset\n",
    "# 2.Taking care of missing data\n",
    "# 3.Encoding categorical data\n",
    "\n",
    "# 4.Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "## random_state, ejemplos random solo para fines educativos\n",
    "x_train, x_test, y_train, y_test = train_test_split(featuresX,featuresY,test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 5.Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)\n",
    "\n",
    "print 'TRAIN DATA'\n",
    "print x_train\n",
    "print y_train\n",
    "\n",
    "print 'TEST DATA'\n",
    "print x_test\n",
    "print y_test\n",
    "\n",
    "# SCIKIT LEARN - SVM\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "_svm = svm.SVC()\n",
    "\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "\n",
    "x_test = x_test\n",
    "\n",
    "_svm.fit(x_train,y_train)\n",
    "\n",
    "val_to_predict = x_test\n",
    "\n",
    "svm_prediction = _svm.predict(val_to_predict)\n",
    "\n",
    "print(\"prediccion svm\", svm_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of black pixels is: 406046\n",
      "The number of red pixels is: 833\n",
      "The number of green pixels is: 679\n",
      "The number of blue pixels is: 1114\n",
      "The number of white pixels is: 2990\n",
      "The number of cian pixels is: 2733\n",
      "The number of magenta pixels is: 2710\n",
      "The number of yellow pixels is: 5376\n",
      "The number of fondo1 pixels is: 44\n",
      "The number of fondo2 pixels is: 22\n"
     ]
    }
   ],
   "source": [
    "# Testeando la dilatacion de colores\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im2 = cv2.imread('images/signatures/drsc/legit_1_x5.jpg')\n",
    "im3 = cv2.imread('images/signatures/drsc/legit_2_x5.jpg')\n",
    "\n",
    "im_merged = cv2.bitwise_xor(im2,im3)\n",
    "\n",
    "cv2.imshow('im2',im2)\n",
    "cv2.imshow('im3',im3)\n",
    "cv2.imshow('merged',im_merged)\n",
    "\n",
    "# NEGRO\n",
    "BLACK_MIN = np.array([0, 0, 0], np.uint8)\n",
    "BLACK_MAX = np.array([50, 50, 50], np.uint8)\n",
    "dst_black = cv2.inRange(im_merged, BLACK_MIN, BLACK_MAX)\n",
    "cv2.imshow('Black',dst_black)\n",
    "no_black = cv2.countNonZero(dst_black)\n",
    "print('The number of black pixels is: ' + str(no_black))\n",
    "\n",
    "# ROJO\n",
    "RED_MIN = np.array([0, 0, 200], np.uint8)\n",
    "RED_MAX = np.array([50, 50, 255], np.uint8)\n",
    "dst_red = cv2.inRange(im_merged, RED_MIN, RED_MAX)\n",
    "cv2.imshow('Red',dst_red)\n",
    "no_red = cv2.countNonZero(dst_red)\n",
    "print('The number of red pixels is: ' + str(no_red))\n",
    "\n",
    "# VERDE\n",
    "GREEN_MIN = np.array([0, 200, 0], np.uint8)\n",
    "GREEN_MAX = np.array([50, 255, 50], np.uint8)\n",
    "dst_green = cv2.inRange(im_merged, GREEN_MIN, GREEN_MAX)\n",
    "cv2.imshow('Green',dst_green)\n",
    "no_green = cv2.countNonZero(dst_green)\n",
    "print('The number of green pixels is: ' + str(no_green))\n",
    "\n",
    "# AZUL\n",
    "BLUE_MIN = np.array([200, 0, 0], np.uint8)\n",
    "BLUE_MAX = np.array([255, 50, 50], np.uint8)\n",
    "dst_blue = cv2.inRange(im_merged, BLUE_MIN, BLUE_MAX)\n",
    "cv2.imshow('Blue',dst_blue)\n",
    "no_blue = cv2.countNonZero(dst_blue)\n",
    "print('The number of blue pixels is: ' + str(no_blue))\n",
    "\n",
    "# BLANCO\n",
    "WHITE_MIN = np.array([200, 200, 200], np.uint8)\n",
    "WHITE_MAX = np.array([255, 255, 255], np.uint8)\n",
    "dst_white = cv2.inRange(im_merged, WHITE_MIN, WHITE_MAX)\n",
    "cv2.imshow('White',dst_white)\n",
    "no_white = cv2.countNonZero(dst_white)\n",
    "print('The number of white pixels is: ' + str(no_white))\n",
    "\n",
    "# CIAN\n",
    "CIAN_MIN = np.array([200, 200, 0], np.uint8)\n",
    "CIAN_MAX = np.array([255, 255, 50], np.uint8)\n",
    "dst_cian = cv2.inRange(im_merged, CIAN_MIN, CIAN_MAX)\n",
    "cv2.imshow('Cian',dst_cian)\n",
    "no_cian = cv2.countNonZero(dst_cian)\n",
    "print('The number of cian pixels is: ' + str(no_cian))\n",
    "\n",
    "# MAGENTA\n",
    "MAGENTA_MIN = np.array([200, 0, 200], np.uint8)\n",
    "MAGENTA_MAX = np.array([255, 50, 255], np.uint8)\n",
    "dst_magenta = cv2.inRange(im_merged, MAGENTA_MIN, MAGENTA_MAX)\n",
    "cv2.imshow('Magenta',dst_magenta)\n",
    "no_magenta = cv2.countNonZero(dst_magenta)\n",
    "print('The number of magenta pixels is: ' + str(no_magenta))\n",
    "\n",
    "# AMARILLO\n",
    "YELLOW_MIN = np.array([0, 200, 200], np.uint8)\n",
    "YELLOW_MAX = np.array([50, 255, 255], np.uint8)\n",
    "dst_yellow= cv2.inRange(im_merged, YELLOW_MIN, YELLOW_MAX)\n",
    "cv2.imshow('Yellow',dst_yellow)\n",
    "no_yellow = cv2.countNonZero(dst_yellow)\n",
    "print('The number of yellow pixels is: ' + str(no_yellow))\n",
    "\n",
    "# FONDO 1\n",
    "FONDO1_MIN = np.array([134, 130, 200], np.uint8)\n",
    "FONDO1_MAX = np.array([183, 180, 255], np.uint8)\n",
    "dst_fondo1= cv2.inRange(im_merged, FONDO1_MIN, FONDO1_MAX)\n",
    "cv2.imshow('Fondo 1',dst_fondo1)\n",
    "no_fondo1 = cv2.countNonZero(dst_fondo1)\n",
    "print('The number of fondo1 pixels is: ' + str(no_fondo1))\n",
    "\n",
    "# FONDO 2\n",
    "FONDO2_MIN = np.array([71, 75, 0], np.uint8)\n",
    "FONDO2_MAX = np.array([121, 125, 50], np.uint8)\n",
    "dst_fondo2= cv2.inRange(im_merged, FONDO2_MIN, FONDO2_MAX)\n",
    "cv2.imshow('Fondo 2',dst_fondo2)\n",
    "no_fondo2 = cv2.countNonZero(dst_fondo2)\n",
    "print('The number of fondo2 pixels is: ' + str(no_fondo2))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features X  [0.56242967, 0.011948956439761292, 0.0072649979378826817, 500, 995, 839, 1410, 7316, 5593, 5306, 11714, 144, 36]\n",
      "Features Y  [1]\n"
     ]
    }
   ],
   "source": [
    "# Vector de Caracteristicas\n",
    "featuresX = [\n",
    "    aspectRatio,\n",
    "    densityRatio,\n",
    "    occupancyRatio,\n",
    "    corners,\n",
    "    no_red,\n",
    "    no_green,\n",
    "    no_blue,\n",
    "    no_white,\n",
    "    no_cian,\n",
    "    no_magenta,\n",
    "    no_yellow,\n",
    "    no_fondo1,\n",
    "    no_fondo2\n",
    "]\n",
    "\n",
    "featuresY = [1]\n",
    "\n",
    "print \"Features X \", featuresX\n",
    "print \"Features Y \", featuresY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### TESTING PREPROCESSING ########\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "cv2.imshow('1.Signature Original', image)\n",
    "cv2.waitKey(0)\n",
    "# A ESCALA DE GRISES\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('2.Signature GrayScale', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# ESCALAMIENTO\n",
    "image = scale(image)\n",
    "cv2.imshow('3.Signature Scaled', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# ELIMINACION DE RUIDO\n",
    "image = cv2.fastNlMeansDenoising(image, None, 6, 7, 21)\n",
    "cv2.imshow('4.Signature Denoised', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# BINARIZACION <127 -> 0 (black), >=127 -> 255 (white)\n",
    "ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('5. Threshold Binary', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# THINING\n",
    "image = thinning(image)\n",
    "cv2.imshow('5. Thinning', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# *** ROTACION ***\n",
    "\n",
    "# *** EROSION ***\n",
    "#kernel = np.ones((5,5), np.uint8)\n",
    "#image = cv2.dilate(image, kernel, iterations = 1)\n",
    "#cv2.imshow(\"7. Erosion\", image)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# *** DILATACION ***\n",
    "#kernel = np.ones((5,5), np.uint8)\n",
    "#image = cv2.erode(image, kernel, iterations = 1)\n",
    "#cv2.imshow(\"6. Dilation\", image)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mu02': 792088982.9336376, 'mu03': 772342436.6479492, 'm11': 14776173335.125, 'nu02': 0.055520862367176155, 'm12': 4465346985876.434, 'mu21': 1255415229.5533447, 'mu20': 1984872112.2666054, 'nu20': 0.13912806987094944, 'm30': 13071571236107.8, 'nu21': 0.0002546186321410142, 'mu11': 64370774.86909294, 'mu12': -10017063627.520874, 'nu11': 0.004512019493995183, 'nu12': -0.0020316234651831535, 'm02': 10016970852.416666, 'm03': 3224823781108.5503, 'm00': 119442.5, 'm01': 33194019.833333332, 'mu30': 33796113766.69336, 'nu30': 0.006854401680326211, 'nu03': 0.00015664361092204086, 'm10': 52937682.33333333, 'm20': 25447192566.25, 'm21': 7130291512179.1}\n",
      "contour area : 119442.5 119442.5\n",
      "Contour perimeter :  1918.23253584\n",
      "centroid :  443 277\n"
     ]
    }
   ],
   "source": [
    "# Contours - Para delimitar la firma\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('images/signatures/drsc/legit_1.jpg',0)\n",
    "img = scale(img)\n",
    "cv2.imshow('Original',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# dilating image\n",
    "kernel = np.ones((100,100), np.uint8)\n",
    "img = cv2.erode(img, kernel, iterations = 1)\n",
    "\n",
    "ret,thresh = cv2.threshold(img,127,255,0)\n",
    "_,contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "\n",
    "# Moments\n",
    "cnt = contours[0]\n",
    "M = cv2.moments(cnt)\n",
    "print M\n",
    "\n",
    "#Centroid\n",
    "cx = int(M['m10']/M['m00'])\n",
    "cy = int(M['m01']/M['m00'])\n",
    "print 'contour area :', M['m00'] , cv2.contourArea(cnt)\n",
    "print 'Contour perimeter : ', cv2.arcLength(cnt,True)\n",
    "print 'centroid : ',cx,cy\n",
    "\n",
    "# Contour Approximation\n",
    "epsilon = 0.1*cv2.arcLength(cnt,True)\n",
    "approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "# Hull\n",
    "hull = cv2.convexHull(cnt)\n",
    "# Bounding Rect\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "img = img[y:y+h,x:x+w]\n",
    "\n",
    "cv2.imshow('Cropping',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('half 1', image[:,:image.shape[1]/2])\n",
    "cv2.imshow('half 2', image[:,image.shape[1]/2:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SCIKIT LEARN - CLEANING DATA\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# 1.Importing the dataset\n",
    "dataset = pd.read_csv('ScikitLearn/Data.csv')\n",
    "\n",
    "## Todas las filas (:), Todas las columnas menos la utima (:-1)\n",
    "x = dataset.iloc[:,:-1].values\n",
    "## Todas las filas (:), La utima columna (-1)\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "# 2.Taking care of missing data\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "## missing_values, se ocupara de los valores que sean NaN (es 'NaN' por default)\n",
    "## strategy, la estrategia que usara para rellenar esos campos  (es 'mean' por default)\n",
    "## axis, si calculara en base a (0, las columnas) o (1, las filas) (es 0 por defecto) \n",
    "## imputer = Imputer(missing_values = 'NaN' , strategy = 'mean', axis = 0)\n",
    "\n",
    "imputer = Imputer()\n",
    "imputer = imputer.fit(x[:,1:])\n",
    "x[:,1:] = imputer.transform(x[:,1:])\n",
    "\n",
    "# 3.Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_x = LabelEncoder()\n",
    "x[:,0] = labelencoder_x.fit_transform(x[:,0])\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "## categorical_features, que columnas queremos categorizar\n",
    "onehotencoder = OneHotEncoder(categorical_features= [0])\n",
    "\n",
    "x = onehotencoder.fit_transform(x).toarray();\n",
    "\n",
    "\n",
    "# 4.Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "## random_state, ejemplos random solo para fines educativos\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 5.Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
       "       [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
       "       [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
       "       [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('prediccion svm', array([ 1,  9, 25, 49, 81]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x6cd7b38>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa2cdf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SCIKIT LEARN - SVM\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#_lr = linear_model.LinearRegression()\n",
    "_svm = svm.SVC()\n",
    "#_nn = neural_network.MLPRegressor(max_iter=100)\n",
    "\n",
    "arr_nums_train = range(1,10,2)\n",
    "arr_nums_test = range(0,10,2)\n",
    "\n",
    "x_train = np.transpose([arr_nums_train])\n",
    "y_train = np.power(arr_nums_train,2)\n",
    "\n",
    "x_test = np.transpose([arr_nums_test])\n",
    "\n",
    "#_lr.fit(x_train,y_train)\n",
    "_svm.fit(x_train,y_train)\n",
    "#_nn.fit(x_train,y_train)\n",
    "\n",
    "val_to_predict = 6\n",
    "\n",
    "#lr_prediction  = _lr.predict(x_test)\n",
    "svm_prediction = _svm.predict(x_test)\n",
    "#nn_prediction  = _nn.predict(x_test)\n",
    "\n",
    "#print(\"prediccion rl\", lr_prediction)\n",
    "print(\"prediccion svm\", svm_prediction)\n",
    "#print(\"prediccion nn\", nn_prediction)\n",
    "\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_test, lr_prediction, color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [3]\n",
      " [5]\n",
      " [7]\n",
      " [9]]\n",
      "[[ 1]\n",
      " [ 9]\n",
      " [25]\n",
      " [49]\n",
      " [81]]\n"
     ]
    }
   ],
   "source": [
    "print x_train\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TESTING MAIN FUNCTION ########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "featuresX = []\n",
    "featuresY = []\n",
    "\n",
    "ruta_imagen = \"images/signatures/drsc/legit_1\"\n",
    "extension_imagen = \".jpg\"\n",
    "image = cv2.imread(ruta_imagen + extension_imagen)\n",
    "image = preprocess(image, True)\n",
    "cv2.imshow('Signature PreProcessed', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img_dilated = dilatex5(image)\n",
    "cv2.imshow('Signature Dilated x5', img_dilated)\n",
    "cv2.imwrite(ruta_imagen+\"_x5\"+extension_imagen, img_dilated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.COLOR_BGR2GRAY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
