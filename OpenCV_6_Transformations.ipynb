{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRANSLATIONS\n",
    "# This is an affine that simply shifts the position of an image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "\n",
    "#Store height and width if the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4 , width/4\n",
    "\n",
    "#     | 1 0 Tx |\n",
    "# T = | 0 1 Ty |\n",
    "\n",
    "# T is our translation matrix\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n",
    "\n",
    "#We use warpAffine to transform the image using the matrix, T\n",
    "img_translation = cv2.warpAffine(image, T , (width,height))\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROTATIONS\n",
    "# cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.png')\n",
    "cv2.imshow('Original image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image around its centre\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2 , height/2), 90, 1)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RE-SIZING, SCALING AND INTERPOLATION\n",
    "# Interpolation is a method of constructing new data point within the range of a discrete set of known data points\n",
    "# cv2.INTER_AREA - Good for shrinking or down sampling\n",
    "# cv2.INTER_NEAREST - Fastest\n",
    "# cv2.INTER_LINEAR - Good for zooming or up sampling (default)\n",
    "# INTER_CUBIC - Better\n",
    "# INTER_LANCZOS4 - Best\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "\n",
    "# Let's make our image 3/4 of it's original size\n",
    "image_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "#Let's double the size of our image\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's skew the re-sizing by setting exact dimensions\n",
    "img_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE PYRAMIDS\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Smaller', smaller)\n",
    "cv2.imshow('Larger', larger)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CROPPING IMAGES\n",
    "# Cropping images refers to extracting a of that image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Let's get the starting pixel coordinates (top left of ropping rectangle)\n",
    "start_row, start_col = int(height * .25) , int(width * .25)\n",
    "\n",
    "# Let's get the ending pixel coordinates (bottom right)\n",
    "end_row, end_col = int(height * .75) , int(width * .75)\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire\n",
    "cropped = image[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Cropped Image\", cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ARITHMETIC OPERATIONS\n",
    "# These area simple operations that allow us to directly add or subtract to the color intensity\n",
    "# Calculates the per-element operation of to arrays, The overall effect is increassing or decreassing grightness\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\")\n",
    "\n",
    "# Create a matrix of ones, then multiply it by a scaler of 100\n",
    "# This gives a matrix with same dimensions of our image width all values being 100\n",
    "M = np.ones(image.shape, dtype = \"uint8\") * 75\n",
    "\n",
    "# We use this to add this matrix M, to our image\n",
    "# Notice the increase in brightness\n",
    "added = cv2.add(image, M)\n",
    "cv2.imshow(\"Added\", added)\n",
    "\n",
    "# Likewise we can also subtract\n",
    "# Notice the decrease in brightness\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow(\"Subtracted\", subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BITWISE OPERATIONS AND MASKING\n",
    "# To demonstrate these operations let's create some simple images\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# if you're wondering why only two dimensions, well this is a grayscale image,\n",
    "# if we doing a colores image, we'd use \n",
    "# rectangle = np.zeros((300,300,3),np.uint8)\n",
    "\n",
    "# Making a square\n",
    "square = np.zeros((300,300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Making a ellipse\n",
    "ellipse = np.zeros((300,300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150,150), (150,150) ,30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# EXPERIMENTING WITH SOME BITWISE OPERATIONS\n",
    "\n",
    "# Show only where they intersect\n",
    "bitwiseAND = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"AND\", bitwiseAND)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows where either square or ellipse is\n",
    "bitwiseOR = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"OR\", bitwiseOR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows where either exists by itself\n",
    "bitwiseXOR = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"XOR\", bitwiseXOR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows everything that isn't part of the square\n",
    "bitwiseNOT_SQUARE = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"NOT - square\", bitwiseNOT_SQUARE)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONVOLUTIONS & BLURRING\n",
    "# A CONVOLUTION is a mathematical operation performed on two functions\n",
    "# producing a thris function which is typically a modified version of one \n",
    "# of the original functions\n",
    "\n",
    "# Output Image = Image x Function_KernelSize\n",
    "\n",
    "# In Computer Vision we use kernel's to specify the size over which \n",
    "# we run our manipulating function over our image\n",
    "\n",
    "# BLURRING\n",
    "# is an operation where we average the pixels within a region (kernel)\n",
    "\n",
    "#               |  1  1  1  1  1  |\n",
    "#               |  1  1  1  1  1  |\n",
    "# Kernel = 1/25 |  1  1  1  1  1  |\n",
    "#               |  1  1  1  1  1  |\n",
    "#               |  1  1  1  1  1  |\n",
    "\n",
    "# The above is a 5 x 5 kernel.\n",
    "# We multiply by 1/25 to normalize i.e. sum to 1, otherwise we'd be increasing intensity.\n",
    "# cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\")\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating our 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "# We use the cv2.filter2D to convolve the kernel with an image\n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating our 7x7 Kernel\n",
    "kernel_7x7 = np.ones((7,7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OTHER COMMONLY USED BLURRING METHODS IN OPENCV\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "\n",
    "# Averaging done by convolving the image with a normalized box filter.\n",
    "# This takes the pixels under the box and replaces the central element\n",
    "# Box size needs to odd and positive\n",
    "# blur - Averages values over specified window\n",
    "blur = cv2.blur(image, (3,3))\n",
    "cv2.imshow(\"Averaging\", blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# instead of box filter , gaussian model\n",
    "# GaussianBlur - Similar, but uses a Gaussian window (more emphasis \n",
    "# or weighting on points around the center)\n",
    "Gaussian = cv2.GaussianBlur(image, (7,7), 0)\n",
    "cv2.imshow(\"Gaussian Blurring\", Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Takes median of all the pixels under kernel area and central \n",
    "# element is replaces with this median value\n",
    "# medianBlur - Uses median of  all elements in the window\n",
    "median = cv2.medianBlur(image, 5)\n",
    "cv2.imshow(\"Median Blurring\", median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "# bilateralFilter - Blur while keeping edges sharp (slower), It also takes a Gaussian filter\n",
    "# in space, but one more Gaussian filter which is a function of pixel difference, The pixel difference\n",
    "# function makes sure only those pixeels with similar intensity to central pixel is \n",
    "# considered for blurring, So it preserver the edges since pixels at edges will have large intensity variation\n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring', bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE DE-NOISING - NON_LOCAL  MEANS DENOISING\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "# Parameters, after None are - the filter strength 'h' (S-10 is a good range)\n",
    "# Next is hForColorComponents, set as same value as h again\n",
    "#\n",
    "# cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "# cv2.fastNlMeansDenoisingColored() - works with a color image\n",
    "# cv2.fastNlMeansDenoisingMulti() - works with a image sequence captured in short period of time (grayscale images)\n",
    "# cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n",
    "\n",
    "cv2.imshow('Fast Means Donising', dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SHARPENING\n",
    "# Sharpening is the opposite of blurring, it strengthens or emphasizing edges in an image\n",
    "# Our kernel matrix sums to one, so there is no need to normalize (i.e multiply by a factor to\n",
    "# retain the same brightness of the original)\n",
    "#          |  -1  -1  -1  |\n",
    "# Kernel = |  -1   9  -1  |  \n",
    "#          |  -1  -1  -1  |\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/signature.jpg')\n",
    "\n",
    "# Create our sharpening kernel, we don't normal normalize since the \n",
    "# values in the matrix sum to 1\n",
    "kernel_sharpening = np.array([\n",
    "    [-1,-1,-1],\n",
    "    [-1, 9,-1],\n",
    "    [-1,-1,-1]\n",
    "])\n",
    "# applying different kernels to the input image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "cv2.imshow('ImageSharpening', sharpened)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THRESHOLDING, BINARIZTION & ADAPTIVE THRESHOLDING\n",
    "# Thresholding is act of converting an image to a binary form.\n",
    "#\n",
    "# cv2.threshold(image, Threshold Value, Max Value, Threshold Type)\n",
    "#\n",
    "# Threshold Types:\n",
    "# cv2.THRESH_BINARY - Most Common\n",
    "# cv2.THRESH_BINARY_INV - Most Common\n",
    "# cv2.THRESH_TRUNC\n",
    "# cv2.THRESH_TOZERO\n",
    "# cv2.THRESH_TOZERO\n",
    "#\n",
    "# NOTE : Image need to be converted to greyscale before thresholding\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image as greyscale\n",
    "image = cv2.imread('images/signature.jpg',0)\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "# Values below 127 goes to 0 (black), everything above goes to 255 (white))\n",
    "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 Threshold Binary', thresh1)\n",
    "\n",
    "# Values below 127 go to 255 and values above 127 go to 0 (reverse of above)\n",
    "ret, thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 Threshold Binary Inverse', thresh2)\n",
    "\n",
    "# Values above 127 are truncated (held) at 127 (the 255 argument is unused)\n",
    "ret, thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('3 THRESH TRUNC', thresh3)\n",
    "\n",
    "# Values below 127 goes to 0 , above 127 are unchanged\n",
    "ret, thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('4 THRESH TOZERO', thresh4)\n",
    "\n",
    "# resever of above, below 127 is unchanged, above 127 goes to 0\n",
    "ret, thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('5 THRESH TOZERO_INV', thresh5)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADAPTIVE THRESHOLDING\n",
    "# - Simple threshold methods take that uncertainty away\n",
    "# - Adaptive threshold methods take that uncertainty away\n",
    "\n",
    "# cv2.adaptiveThreshold(image, Max value, Adaptive type, Threshold Type, Block size, Constant that is subtracted from mean)\n",
    "# NOTE: Block sizes need to be odd numbers!\n",
    "#\n",
    "# Adaptive Threshold Types:\n",
    "# ADAPTIVE_THRESH_MEAN_C - based on mean of the neighboorhodd of pixels\n",
    "# ADAPTIVE_THRESH_GAUSSIAN_C - weighted sum of neighborhood pixels under the Gaussian window\n",
    "# THRESH_OTSU (uses cv2.threshold function) - Clever algorithm assumes there are two peaks in the gray scale Histrogram\n",
    "# of the image and then tries to find an optimal value to separate these two peaks to find T.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image as greyscale\n",
    "image = cv2.imread('images/signature.jpg',0)\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 goes to 0 (black), everything above goes to 255 (white))\n",
    "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# It's good practice to blur images as it removes noise\n",
    "image = cv2.GaussianBlur(image, (3,3) , 0)\n",
    "\n",
    "# Using adaptive threshold\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5)\n",
    "cv2.imshow(\"Adaptive Mean Thresholding\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "_, th2 = cv2.threshold(image,0 ,255 ,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu's Thresholding\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Gaussian Otsu's Thresholding\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DILATION AND EROSION\n",
    "# These are operations in the field of mathematical morphology\n",
    "# Dilation - Adds pixels to the boundaries of objects in an image\n",
    "# Erosion  - Removes pixels at the boundaries of object in an image\n",
    "# Opening  - Erosion followed by dilation\n",
    "# Closing  - Dilation folowwed by erosion\n",
    "\n",
    "# Common StackOverflow question : \"Why is dilation and erosion doing the reverse of what I expect?\"\n",
    "# Remember\n",
    "# Dilation - Adds pixels to the boundaries of objects in an image\n",
    "# Erosion - Removes pixels at the boundaries of object in an image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\")\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's define our kernel size\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# dilation\n",
    "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"Opening\", opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Closing - Good for removing noise\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"Closing\", closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# There are some other less popular morphology operations, see the official OpenCV site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDGE DETECTION & IMAGE GRADIENTS\n",
    "\n",
    "# Edge Detection is a very important area in Computer Vision, expecially when\n",
    "# dealing with contours (you'll learn this later soon)\n",
    "# Edges can be defined as sudden changes (discontinuities) in an image and they can encode just as much information as pixels\n",
    "\n",
    "# Edge Detection Algorithms\n",
    "# There are three types of Edge Detection\n",
    "# - Sobel - to emphasize vertical or horizontal edges\n",
    "# - Laplacion - Gets all orientations\n",
    "# - Canny - Optimal due to low error rate, well defines edges and accurate detection\n",
    "\n",
    "# Canny Edge Detection Algorithm (developed by John F. Canny in 1986)\n",
    "\n",
    "# 1. Applies Gaussian bluring\n",
    "# 2. Finds intensity gradient of the image\n",
    "# 3. Applied non-maximum suppression (i.e removes pixels that are not edges)\n",
    "# 4. Hysteresis - Aplies thresholds (i.e. if pixel is tithin the upper and lower thresholds, it's considered an edge)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\",0)\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "# Extract Sobel Edges\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('sobel_OR', sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow(\"Laplacian\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Then, we need to provide two values: threshold1 and threshold2, Any gradient value larger than threshold2\n",
    "# is considered to be an edge. Any value below threshold is considered not to be an edge.\n",
    "# values in between threshold1 and threshold2 are either classified as edge or non-edges based on how their\n",
    "# intensities are \"connected\". in this case, any gradient values below 60 are considered non-edges\n",
    "# whereas any values above 120 are considered edges.\n",
    "\n",
    "# Canny Edge Detection uses gradient values as thresholds\n",
    "# The first threshold gradient\n",
    "canny = cv2.Canny(image, 20, 170)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PERSPECTIVE AND AFFINE TRANSFORMS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\")\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cordinates of the 4 corners of the original image\n",
    "points_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# We use a ratio of an A4 Paper 1 : 1.41\n",
    "points_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n",
    "\n",
    "# Use the two sets of four points to compute\n",
    "# the Perspective Transformation matrix, M\n",
    "M = cv2.getPerspectiveTransform(points_A, points_B)\n",
    "\n",
    "warped = cv2.warpPerspective(image, M, (420, 594))\n",
    "\n",
    "cv2.imshow(\"warpPerspective\", warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In Affine transforms you only need 3 coordinates to obtain the correct transform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"images/signature.jpg\")\n",
    "rows, cols, ch = image.shape\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cordinates of the 4 corners of the original image\n",
    "points_A = np.float32([[320,15], [700,215], [85,610]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# we use a ratio of an A4 paper 1 : 1.41\n",
    "points_B = np.float32([[0,0], [420,0], [0,594]])\n",
    "\n",
    "# Use the two sets of your points to compute\n",
    "# the perspective Transformation matrix, M\n",
    "M = cv2.getAffineTransform(points_A, points_B)\n",
    "\n",
    "warped = cv2.warpAffine(image, M, (cols,rows))\n",
    "\n",
    "cv2.imshow(\"warpPerspective\", warped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
